{"cells":[{"cell_type":"markdown","metadata":{"id":"46Rt7B4V5769"},"source":["\n","<br>\n","    Transformer 101 > Encoder Part Implementation<br>\n","        - this code is for educational purpose.<br>\n","        - the code is written for easy understanding not for optimized code.<br>\n","    Author : Sangkeun Jung (hugmanskj@gmai.com)<br>\n","    All rights reserved. (2021)<br>\n"]},{"cell_type":"markdown","metadata":{"id":"wkPKyeNr576_"},"source":["In this code, we will implement<br>\n","  - Transformer Encoder Part (only single layer)<br>\n","  - Especially, we will focus on <br>\n","      - Residual Connection<br>\n","      - Layer Normalization<br>\n","      - Scaling <br>\n","  - We re-use and wrapped pre-implemented Dot-QKV-Multihead Attention process<br>\n","  - By doing this, we will remove 'LSTM' part for sequence encoding"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ub6xta7R6O2k","executionInfo":{"status":"ok","timestamp":1656498195918,"user_tz":-540,"elapsed":2712,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"57e195b1-dc84-4771-8d13-5c7de91f221e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/colab/DL_NLP_101/Part3_Transformer_101/practice\")\n","print(os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKHFoPdV6RaI","executionInfo":{"status":"ok","timestamp":1656498196369,"user_tz":-540,"elapsed":456,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"f90f17e2-39ed-46ab-ac46-b41f60605506"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/colab/DL_NLP_101/Part3_Transformer_101/practice\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"bJIuC_ic577A","executionInfo":{"status":"ok","timestamp":1656498199493,"user_tz":-540,"elapsed":3126,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"ugj5TdR0577B"},"source":[" ------------------------------------------------------------------------ ##<br>\n"," Training and Testing with toy dataset                                    ##<br>\n"," ------------------------------------------------------------------------ ##"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTyUqJ_k577H","executionInfo":{"status":"ok","timestamp":1656498210152,"user_tz":-540,"elapsed":10682,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"864dcd30-b04d-47f7-99ca-ead4b5c225f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n","\u001b[K     |████████████████████████████████| 585 kB 5.2 MB/s \n","\u001b[?25hCollecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.17.3)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n","Collecting PyYAML>=5.4\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.6 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 68.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 52.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.46.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.7)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.1.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 75.6 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 74.1 MB/s \n","\u001b[?25hInstalling collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 torchmetrics-0.9.1 yarl-1.7.2\n"]}],"source":["!pip install pytorch_lightning\n","import pytorch_lightning as pl\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"hO72T0NO577J","executionInfo":{"status":"ok","timestamp":1656498210153,"user_tz":-540,"elapsed":22,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["def load_data(fn):\n","    data = []\n","    with open(fn, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            line = line.rstrip()\n","            query_item_seq_str, y = line.split('\\t')\n","            all_tokens = query_item_seq_str.split(',')\n","            q_tokens = all_tokens[0].split('|')\n","            i_tokens = all_tokens[1:]\n","            tokens = [q_tokens[0], '|'] + [q_tokens[1]] + i_tokens \n","            data.append( (tokens, y) )\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"zUO0YwuJ577K"},"source":["you can define any type of dataset<br>\n","dataset : return an example for batch construction. "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"RM-Xn7W6577L","executionInfo":{"status":"ok","timestamp":1656498210153,"user_tz":-540,"elapsed":21,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["class NumberDataset(Dataset):\n","    \"\"\"Dataset.\"\"\"\n","    def __init__(self, fn, input_vocab, output_vocab, max_seq_length):\n","        self.input_vocab = input_vocab\n","        self.output_vocab = output_vocab\n","        self.max_seq_length = max_seq_length \n","        \n","        # load \n","        self.data = load_data(fn)\n","    def __len__(self):\n","        return len(self.data) \n","    def __getitem__(self, idx): \n","        seq, y = self.data[idx]\n","\n","        # [ input ]\n","        seq_ids = [ self.input_vocab[t] for t in seq ]\n","\n","        # <pad> processing\n","        pad_id      = self.input_vocab['<pad>']\n","        num_to_fill = self.max_seq_length - len(seq)\n","        seq_ids     = seq_ids + [pad_id]*num_to_fill\n","\n","        # mask processing (1 for valid, 0 for invalid)\n","        weights = [1]*len(seq) + [0]*num_to_fill\n","\n","        # [ ouput ] \n","        y_id = self.output_vocab[y]\n","        item = [\n","                    # input\n","                    np.array(seq_ids),\n","                    np.array(weights),\n","                    # output\n","                    y_id\n","               ]\n","        return item "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"P_KdsBzV577Q","executionInfo":{"status":"ok","timestamp":1656498210154,"user_tz":-540,"elapsed":22,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["class NumberDataModule(pl.LightningDataModule):\n","    def __init__(self, \n","                 max_seq_length: int=15,\n","                 batch_size: int = 32):\n","        super().__init__()\n","        self.batch_size = batch_size\n","        self.max_seq_length = max_seq_length \n","        input_vocab, output_vocab = self.make_vocab('./data/numbers/train.seq.txt')\n","        self.input_vocab_size = len( input_vocab )\n","        self.output_vocab_size = len( output_vocab )\n","        self.padding_idx = input_vocab['<pad>']\n","        self.input_r_vocab  = { v:k for k,v in input_vocab.items() }\n","        self.output_r_vocab = { v:k for k,v in output_vocab.items() }\n","        self.all_train_dataset = NumberDataset('./data/numbers/train.seq.txt', input_vocab, output_vocab, max_seq_length)\n","        self.test_dataset      = NumberDataset('./data/numbers/test.seq.txt', input_vocab, output_vocab, max_seq_length)\n","\n","        # random split train / valiid for early stopping\n","        N = len(self.all_train_dataset)\n","        tr = int(N*0.8) # 8 for the training\n","        va = N - tr     # 2 for the validation \n","        self.train_dataset, self.valid_dataset = torch.utils.data.random_split(self.all_train_dataset, [tr, va])\n","    def make_vocab(self, fn):\n","        input_tokens = []\n","        output_tokens = []\n","        data = load_data(fn)\n","        for tokens, y in data:\n","            for token in tokens:\n","                input_tokens.append(token)\n","            output_tokens.append(y)\n","        \n","        input_tokens = list(set(input_tokens))\n","        output_tokens = list(set(output_tokens)) \n","        input_tokens.sort()\n","        output_tokens.sort()\n","\n","        # [input vocab]\n","        # add <pad> symbol to input tokens as a first item\n","        input_tokens = ['<pad>'] + input_tokens \n","        input_vocab = { str(token):index for index, token in enumerate(input_tokens) }\n","\n","        # [output voab]\n","        output_vocab = { str(token):index for index, token in enumerate(output_tokens) }\n","        return input_vocab, output_vocab\n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True) # NOTE : Shuffle\n","    def val_dataloader(self):\n","        return DataLoader(self.valid_dataset, batch_size=self.batch_size)\n","    def test_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.batch_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"WEPd8itI577S","executionInfo":{"status":"ok","timestamp":1656498210154,"user_tz":-540,"elapsed":21,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["from torchmetrics import functional as FM"]},{"cell_type":"markdown","metadata":{"id":"S4G0ne0v577S"},"source":[" reused "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"JUAogeZ_577T","executionInfo":{"status":"ok","timestamp":1656498210155,"user_tz":-540,"elapsed":22,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["from attentions import Attention"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2M5u8X_m577T","executionInfo":{"status":"ok","timestamp":1656498210156,"user_tz":-540,"elapsed":23,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    # - a single layer for Transformer-Encoder block\n","    # - This Encoder block is almost identical to original transformer block\n","    # - activation function is changed to RELU \n","    #       - (note that, recently RELU is frequently replaced as GELU)\n","    def __init__(self, d_model, num_head, dim_feedforward, dropout=0.1):\n","        super(TransformerEncoderLayer, self).__init__()\n","        self.dropout = dropout\n","\n","        # self-attention\n","        self.self_attn = Attention(d_model, num_head, dropout)\n","\n","        # MLP\n","        self.act_fc = nn.GELU() # <- I changed RELU to GELU \n","        self.fc1 = nn.Linear(d_model, dim_feedforward)\n","        self.fc2 = nn.Linear(dim_feedforward, d_model)\n","\n","        # LN for after attention and final \n","        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n","        self.final_layer_norm     = nn.LayerNorm(d_model)\n","    def forward(self, x, mask):\n","        # 1) self-multihead-attention with add & norm \n","        residual = x\n","        x, attn_scores = self.self_attn(query=x, key=x, value=x, mask=mask)\n","        x = F.dropout(x, self.dropout, training=self.training)\n","        x = residual + x \n","        x = self.self_attn_layer_norm(x) # POST Layer Normalization\n","\n","        # 2) MLP with add & norm\n","        residual = x\n","        x = self.act_fc(self.fc1(x))\n","        x = F.dropout(x, self.dropout, training=self.training)\n","        x = self.fc2(x)\n","        x = F.dropout(x, self.dropout, training=self.training)\n","        x = residual + x \n","        x = self.final_layer_norm(x)     # POST Layer Normalization\n","\n","        # out : [batch_size, step_size=S, d_model]\n","        # step_size = max_seq_len .. \n","        return x, attn_scores"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"CWuugAXF577U","executionInfo":{"status":"ok","timestamp":1656498210159,"user_tz":-540,"elapsed":25,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["class TransformerEncoder_Number_Finder(pl.LightningModule): \n","    def __init__(self, \n","                 # network setting\n","                 input_vocab_size,\n","                 output_vocab_size,\n","                 d_model,      # dim. in attemtion mechanism \n","                 num_heads,    # number of heads\n","                 padding_idx,\n","                 # optiimzer setting\n","                 learning_rate=1e-3):\n","        super().__init__()\n","        self.save_hyperparameters()  \n","\n","        # symbol_number_character to vector_number\n","        self.input_emb = nn.Embedding(self.hparams.input_vocab_size, \n","                                      self.hparams.d_model, \n","                                      padding_idx=self.hparams.padding_idx)\n","\n","        # Now, we use transformer-encoder for encoding\n","        #   - multiple items and a query item together\n","        self.encoder = TransformerEncoderLayer( self.hparams.d_model, \n","                                                self.hparams.num_heads, \n","                                                dim_feedforward=self.hparams.d_model*4, # by convention\n","                                                dropout=0.1\n","                                              )\n","        # [to output]\n","        self.to_output = nn.Linear(self.hparams.d_model, self.hparams.output_vocab_size) # D -> a single number\n","\n","        # loss\n","        self.criterion = nn.CrossEntropyLoss()  \n","    def forward(self, seq_ids, weight):\n","        # INPUT EMBEDDING\n","        # [ Digit Character Embedding ]\n","        # seq_ids : [B, max_seq_len]\n","        seq_embs = self.input_emb(seq_ids.long()) # [B, max_seq_len, d_model]\n","\n","        # ENCODING BY Transformer-Encoder\n","        # [mask shaping]\n","        # masking - shape change\n","        #   mask always applied to the last dimension explicitly. \n","        #   so, we need to prepare good shape of mask\n","        #   to prepare [B, dummy_for_heads, dummy_for_query, dim_for_key_dimension]\n","        mask = weight[:, None, None, :] # [B, 1, 1, max_seq_len]\n","        seq_encs, attention_scores = self.encoder(seq_embs, mask) # [B, max_seq_len, d_model] \n","\n","        # seq_encs         : [B, max_seq_len, d_model]\n","        # attention_scores : [B, max_seq_len_query, max_seq_len_key]\n","\n","        # Output Processing\n","        # pooling \n","        blendded_vector = seq_encs[:,0]  # taking the first(query) - step hidden state\n","        \n","        # To output\n","        logits = self.to_output(blendded_vector)\n","        return logits, attention_scores\n","    def training_step(self, batch, batch_idx):\n","        seq_ids, weights, y_id = batch \n","        logits, _ = self(seq_ids, weights)  # [B, output_vocab_size]\n","        loss = self.criterion(logits, y_id.long()) \n","        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","\n","        # all logs are automatically stored for tensorboard\n","        return loss\n","    def validation_step(self, batch, batch_idx):\n","        seq_ids, weights, y_id = batch \n","        logits, _ = self(seq_ids, weights)  # [B, output_vocab_size]\n","        loss = self.criterion(logits, y_id.long()) \n","        \n","        ## get predicted result\n","        prob = F.softmax(logits, dim=-1)\n","        acc = FM.accuracy(prob, y_id)\n","        metrics = {'val_acc': acc, 'val_loss': loss}\n","        self.log_dict(metrics)\n","        return metrics\n","    def validation_step_end(self, val_step_outputs):\n","        val_acc  = val_step_outputs['val_acc'].cpu()\n","        val_loss = val_step_outputs['val_loss'].cpu()\n","        self.log('validation_acc',  val_acc, prog_bar=True)\n","        self.log('validation_loss', val_loss, prog_bar=True)\n","    def test_step(self, batch, batch_idx):\n","        seq_ids, weights, y_id = batch \n","        logits, _ = self(seq_ids, weights)  # [B, output_vocab_size]\n","        loss = self.criterion(logits, y_id.long()) \n","        \n","        ## get predicted result\n","        prob = F.softmax(logits, dim=-1)\n","        acc = FM.accuracy(prob, y_id)\n","        metrics = {'test_acc': acc, 'test_loss': loss}\n","        self.log_dict(metrics, on_epoch=True)\n","        return metrics\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n","        return optimizer\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):\n","        parser = parent_parser.add_argument_group(\"ATTENTION\")\n","        parser.add_argument('--learning_rate', type=float, default=0.0001)\n","        return parent_parser"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"99QLuBKn577V","executionInfo":{"status":"ok","timestamp":1656498210454,"user_tz":-540,"elapsed":320,"user":{"displayName":"정진우","userId":"02706839958698409454"}}},"outputs":[],"source":["from argparse import ArgumentParser\n","from pytorch_lightning.callbacks import EarlyStopping\n","def cli_main():\n","    pl.seed_everything(1234)\n","\n","    # ------------\n","    # args\n","    # ------------\n","    # parser = ArgumentParser()\n","    # parser.add_argument('--batch_size', default=200, type=int)\n","    # parser.add_argument('--d_model',    default=512, type=int)  # dim. for attention model \n","    # parser.add_argument('--num_heads',  default=8, type=int)    # number of multi-heads\n","    # parser = pl.Trainer.add_argparse_args(parser)\n","    # parser = TransformerEncoder_Number_Finder.add_model_specific_args(parser)\n","    # args = parser.parse_args()\n","\n","    import easydict\n","\n","    args = easydict.EasyDict({\n"," \n","        \"batch_size\": 200,\n","        \"d_model\": 512,\n","        \"learning_rate\" : 0.0001,\n","        \"num_heads\": 8\n","    })\n","    # ------------\n","    # data\n","    # ------------\n","    dm = NumberDataModule.from_argparse_args(args)\n","    iter(dm.train_dataloader()).next() # <for testing \n","      # ------------\n","    # model\n","    # ------------\n","    model = TransformerEncoder_Number_Finder(\n","                                                dm.input_vocab_size,\n","                                                dm.output_vocab_size,\n","                                                args.d_model,       # dim. in attemtion mechanism \n","                                                args.num_heads,\n","                                                dm.padding_idx,\n","                                                args.learning_rate\n","                                            )\n","\n","    # ------------\n","    # training\n","    # ------------\n","    trainer = pl.Trainer(\n","                            max_epochs=2, \n","                            callbacks=[EarlyStopping(monitor='val_loss')],\n","                            gpus = 1 # if you have gpu -- set number, otherwise zero\n","                        )\n","    trainer.fit(model, datamodule=dm)\n","\n","    # ------------\n","    # testing\n","    # ------------\n","    result = trainer.test(model, test_dataloaders=dm.test_dataloader())\n","    print(result)\n","\n","    # {'test_acc': 0.9998000264167786, 'test_loss': 0.0011931280605494976}\n","   "]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":725,"referenced_widgets":["171bc0da5ba64108a9ce83cc37b9437f","9c16d7482f894b4dba91e67cfb4e1263","a2d5cf9e1c204794af36dda18990b0e0","7c34cab5b4424b098d8a7241f0f71f2b","db3a5c04dd444aeba60068d100379176","763bd7db4871430e8091e25ca6b17713","f8cd6d57cec645cf9b9ab9c94bccbb28","9f96f501b421493882b8d0f4821cdfa3","ee476d42a3314ffb90573e55ac0dad32","1ed6d818ff2740a28308aed66f89e9ea","b03e4f0f92b9473381980b886206db46","e39cd953e19d49adbc75c9764fd79590","8dc39c0b86af4cb9874f57c9ecc8b7da","f0cd6d3313084414a805c568c3051b6f","9a68482d21f34ddea3e56513653fc0a7","f4c8ad64aa984062b0d8c7cb6e6d50c8","98610f2f69ac4a24ad9d8310f3628058","ae89127a5e9b4257820d9bcabd5d0bf9","b31537a396954f9c9cadb6df1e880930","e15b8f06663848b78d7f6f309aaa7989","73929540c4f84728a63e14880ff81c32","b9917746d6d441aeacd529ceeb5d997c","68c5d78a6e54475ca0eaa048d7863e73","b918781a40df439080d31326e17fc55d","c67852576d6440a0b673840df96c834c","85c196b48e624bc7bf783d93c013a30a","c622e0ed4558419a96dbadb0e5552fb5","33be9b266b4c4bfea660b0ade7638fdb","1a7f5368d1e64c8e87ba23e13b4c5356","17cced9c990549a2889f703f81617ef0","d14cd4a841d5417796a39c67a77a87b5","5da3e47ca1aa4589ae6bcf90c0b189a1","243854cdbcfb4d0da61e7b1f978b0854","5dd2a9c100be4c54859cdd426f001807","4503cf4f6f2548c986a64be3d9342e85","47cd7858deab49a9abcbf9881a705678","2e03aaac5d6c4acc9e2cba96c04e1f35","8929ee0ba4504f8da80a2fc559ad9c7a","1438f4dce1bb4f90862eda5d10b4d31f","df361e0ee5dd4974ad98d1cab647d9fa","222f3cd3e3d54600ad76bc33ed726c2e","513ccbc9764947ff9b82556ef41adfb6","d209d23bac0a48859baab910508bcab2","cf5f137275ae4363ab0e36f53761a606"]},"id":"cegPtDtR577W","executionInfo":{"status":"error","timestamp":1656498239617,"user_tz":-540,"elapsed":29179,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"638973d3-f6db-4710-8182-d7b460bc0312"},"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 1234\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name      | Type                    | Params\n","------------------------------------------------------\n","0 | input_emb | Embedding               | 6.1 K \n","1 | encoder   | TransformerEncoderLayer | 3.2 M \n","2 | to_output | Linear                  | 4.6 K \n","3 | criterion | CrossEntropyLoss        | 0     \n","------------------------------------------------------\n","3.2 M     Trainable params\n","0         Non-trainable params\n","3.2 M     Total params\n","12.653    Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171bc0da5ba64108a9ce83cc37b9437f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39cd953e19d49adbc75c9764fd79590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68c5d78a6e54475ca0eaa048d7863e73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd2a9c100be4c54859cdd426f001807"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-5c7632da619f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcli_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-692885762a3d>\u001b[0m in \u001b[0;36mcli_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# ------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: test() got an unexpected keyword argument 'test_dataloaders'"]}],"source":["if __name__ == '__main__':\n","    cli_main()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"02_transformer_encoder.ipynb","provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"171bc0da5ba64108a9ce83cc37b9437f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c16d7482f894b4dba91e67cfb4e1263","IPY_MODEL_a2d5cf9e1c204794af36dda18990b0e0","IPY_MODEL_7c34cab5b4424b098d8a7241f0f71f2b"],"layout":"IPY_MODEL_db3a5c04dd444aeba60068d100379176"}},"9c16d7482f894b4dba91e67cfb4e1263":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_763bd7db4871430e8091e25ca6b17713","placeholder":"​","style":"IPY_MODEL_f8cd6d57cec645cf9b9ab9c94bccbb28","value":"Sanity Checking DataLoader 0: 100%"}},"a2d5cf9e1c204794af36dda18990b0e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f96f501b421493882b8d0f4821cdfa3","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee476d42a3314ffb90573e55ac0dad32","value":2}},"7c34cab5b4424b098d8a7241f0f71f2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed6d818ff2740a28308aed66f89e9ea","placeholder":"​","style":"IPY_MODEL_b03e4f0f92b9473381980b886206db46","value":" 2/2 [00:00&lt;00:00, 10.91it/s]"}},"db3a5c04dd444aeba60068d100379176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"763bd7db4871430e8091e25ca6b17713":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8cd6d57cec645cf9b9ab9c94bccbb28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f96f501b421493882b8d0f4821cdfa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee476d42a3314ffb90573e55ac0dad32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ed6d818ff2740a28308aed66f89e9ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b03e4f0f92b9473381980b886206db46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e39cd953e19d49adbc75c9764fd79590":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8dc39c0b86af4cb9874f57c9ecc8b7da","IPY_MODEL_f0cd6d3313084414a805c568c3051b6f","IPY_MODEL_9a68482d21f34ddea3e56513653fc0a7"],"layout":"IPY_MODEL_f4c8ad64aa984062b0d8c7cb6e6d50c8"}},"8dc39c0b86af4cb9874f57c9ecc8b7da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98610f2f69ac4a24ad9d8310f3628058","placeholder":"​","style":"IPY_MODEL_ae89127a5e9b4257820d9bcabd5d0bf9","value":"Epoch 1: 100%"}},"f0cd6d3313084414a805c568c3051b6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b31537a396954f9c9cadb6df1e880930","max":225,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e15b8f06663848b78d7f6f309aaa7989","value":225}},"9a68482d21f34ddea3e56513653fc0a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73929540c4f84728a63e14880ff81c32","placeholder":"​","style":"IPY_MODEL_b9917746d6d441aeacd529ceeb5d997c","value":" 225/225 [00:04&lt;00:00, 52.26it/s, loss=0.00311, v_num=3, train_loss_step=0.00121, validation_acc=1.000, validation_loss=0.000675, train_loss_epoch=0.0036]"}},"f4c8ad64aa984062b0d8c7cb6e6d50c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"98610f2f69ac4a24ad9d8310f3628058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae89127a5e9b4257820d9bcabd5d0bf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b31537a396954f9c9cadb6df1e880930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e15b8f06663848b78d7f6f309aaa7989":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73929540c4f84728a63e14880ff81c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9917746d6d441aeacd529ceeb5d997c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68c5d78a6e54475ca0eaa048d7863e73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b918781a40df439080d31326e17fc55d","IPY_MODEL_c67852576d6440a0b673840df96c834c","IPY_MODEL_85c196b48e624bc7bf783d93c013a30a"],"layout":"IPY_MODEL_c622e0ed4558419a96dbadb0e5552fb5"}},"b918781a40df439080d31326e17fc55d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33be9b266b4c4bfea660b0ade7638fdb","placeholder":"​","style":"IPY_MODEL_1a7f5368d1e64c8e87ba23e13b4c5356","value":"Validation DataLoader 0: 100%"}},"c67852576d6440a0b673840df96c834c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_17cced9c990549a2889f703f81617ef0","max":45,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d14cd4a841d5417796a39c67a77a87b5","value":45}},"85c196b48e624bc7bf783d93c013a30a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5da3e47ca1aa4589ae6bcf90c0b189a1","placeholder":"​","style":"IPY_MODEL_243854cdbcfb4d0da61e7b1f978b0854","value":" 45/45 [00:00&lt;00:00, 98.66it/s]"}},"c622e0ed4558419a96dbadb0e5552fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"33be9b266b4c4bfea660b0ade7638fdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a7f5368d1e64c8e87ba23e13b4c5356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17cced9c990549a2889f703f81617ef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14cd4a841d5417796a39c67a77a87b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5da3e47ca1aa4589ae6bcf90c0b189a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"243854cdbcfb4d0da61e7b1f978b0854":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dd2a9c100be4c54859cdd426f001807":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4503cf4f6f2548c986a64be3d9342e85","IPY_MODEL_47cd7858deab49a9abcbf9881a705678","IPY_MODEL_2e03aaac5d6c4acc9e2cba96c04e1f35"],"layout":"IPY_MODEL_8929ee0ba4504f8da80a2fc559ad9c7a"}},"4503cf4f6f2548c986a64be3d9342e85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1438f4dce1bb4f90862eda5d10b4d31f","placeholder":"​","style":"IPY_MODEL_df361e0ee5dd4974ad98d1cab647d9fa","value":"Validation DataLoader 0: 100%"}},"47cd7858deab49a9abcbf9881a705678":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_222f3cd3e3d54600ad76bc33ed726c2e","max":45,"min":0,"orientation":"horizontal","style":"IPY_MODEL_513ccbc9764947ff9b82556ef41adfb6","value":45}},"2e03aaac5d6c4acc9e2cba96c04e1f35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d209d23bac0a48859baab910508bcab2","placeholder":"​","style":"IPY_MODEL_cf5f137275ae4363ab0e36f53761a606","value":" 45/45 [00:00&lt;00:00, 98.52it/s]"}},"8929ee0ba4504f8da80a2fc559ad9c7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"1438f4dce1bb4f90862eda5d10b4d31f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df361e0ee5dd4974ad98d1cab647d9fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"222f3cd3e3d54600ad76bc33ed726c2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"513ccbc9764947ff9b82556ef41adfb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d209d23bac0a48859baab910508bcab2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf5f137275ae4363ab0e36f53761a606":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}