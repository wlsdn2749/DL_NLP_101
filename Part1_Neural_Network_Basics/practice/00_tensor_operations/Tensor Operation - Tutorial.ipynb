{"cells":[{"cell_type":"markdown","metadata":{"id":"Ts-Zs_NY_1_j"},"source":["# Deep Learning - Tensor Manipulation"]},{"cell_type":"markdown","metadata":{"id":"juQk518j_2AG"},"source":["### Author : Sangkeun Jung (hugmanskj@gmail.com)"]},{"cell_type":"markdown","metadata":{"id":"9IVG_9Q1_2AH"},"source":["In this tutorial, students can learn various tensor operations and handling techniques. I selected most frequentaly used and most fundamental tensor operations. This is the core part of deep learning, so please take a time to understand and practice the codes. \n","\n","The codes are based on PyTorch, and some operations, grammars are very specific to PyTorch. However, the concepts and the way of handling tensors are common in other machine learning frameworks such as tensorflow or mxnet. "]},{"cell_type":"markdown","metadata":{"id":"dAcskwev_2AK"},"source":["### Table of Contents"]},{"cell_type":"markdown","metadata":{"id":"L3jBZdCq_2AK"},"source":["We can roughly categorize the data handling with following types :\n","\n","- Tensor\n","    - Tensor Creation\n","        - Python object to Tensor Object\n","        - Numpy object to Tensor object\n","        - Tensor Types\n","    - Tensor Shape\n","        - check shape\n","        - reshape\n","        - view\n","    - Tensor Device Change\n","        - cpu or CUDA\n","    - Tensor Data Fetch\n","        - Tensor data to Python object\n","        - Tensor data to Numpy object\n","        - Tensor scalar to Python object (item)\n","- 1 to N Operations ( a Tensor → a list of Tensors )\n","- N to 1 Operations ( a list of Tensors → a Tensor )\n","- Dimension Operations\n","    - squeeze\n","    - unsqueeze\n","    - permutation\n","    - transpose\n","    - ...\n","- Indexing\n","- Reduce Operations\n","    - min, max, mean\n","    - argmax, argmin\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wi8g7h_a_2AN"},"source":["## Tensor Creation"]},{"cell_type":"markdown","metadata":{"id":"5b6LQK-9_2AN"},"source":["#### Python Object to Tensor\n","\n","In python, we have several types of python-objecs to express **number**.\n","- scalar (integer, float)\n","- array ( list ) \n","\n","We can simply create tensor with following operations.\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9z_K_7E_2AS","executionInfo":{"status":"ok","timestamp":1655877732959,"user_tz":-540,"elapsed":10,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"5b2a6764-d74d-433e-fe94-3c7b99eabe5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'float'>\n","<class 'torch.Tensor'>\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(34.)"]},"metadata":{},"execution_count":13}],"source":["import torch \n","# float variable to tensor object\n","x = 34.0 # float value python object\n","print( type(x) ) # float python object\n","y = torch.tensor(x) # torch.tensor(x) -> pytouch object tensor x\n","print( type(y) ) # torch.Tensor object\n","y # tensor(x) values"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOArVSg-_2Aa","executionInfo":{"status":"ok","timestamp":1655877701098,"user_tz":-540,"elapsed":105,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"572cc38d-048b-4a25-ab56-84044805cb80"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(34.)"]},"metadata":{},"execution_count":2}],"source":["# directly create tensor \n","y = torch.tensor(34.0) # float values automatically identified \n","print( type(y) ) # Tensor values pytouch\n","y"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sFsHm96_2Af","executionInfo":{"status":"ok","timestamp":1655877873193,"user_tz":-540,"elapsed":293,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"4d45607a-c59d-4623-b2db-3c22b7b005f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n","<class 'torch.Tensor'>\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([1, 2, 3, 4])"]},"metadata":{},"execution_count":14}],"source":["# list --> tensor\n","x = [1,2,3,4] # python list\n","y = torch.tensor(x) # python object list to pytouch tensor list objects\n","print( type(x) ) # list \n","print( type(y) ) # torch.Tensor 변수든 리스트든 모든 변수들은 다 Tensor shape이 다르다\n","y"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qIupEiHQ_2Ai","executionInfo":{"status":"ok","timestamp":1655877986773,"user_tz":-540,"elapsed":307,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"25130ed4-f606-4205-87ce-6197ba08562c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2, 3, 4],\n","        [5, 6, 7, 8]])\n","torch.Size([2, 4])\n","torch.Size([2, 4])\n"]}],"source":["# list of list --> tensor\n","x = [ \n","      [1,2,3,4], \n","      [5,6,7,8]\n","    ]  # 2 dimensional array\n","print( torch.tensor(x) )\n","print( torch.tensor(x).shape ) # shape 와 size()의 결과는 같다\n","print( torch.tensor(x).size() ) #  torch.Size([2, 4]) -> 2차원 리스트에 각 리스트에 4개의 data 2x4\n"]},{"cell_type":"markdown","metadata":{"id":"wbdgu0Kn_2Ak"},"source":["#### Numpy  Object to Tensor\n","\n","If you are familar with numpy, PyTorch tensor is very easy to understand since most of the pytorch API are just GPU-computable clones of numpy. "]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JO5H2Sgd_2Al","executionInfo":{"status":"ok","timestamp":1655879111359,"user_tz":-540,"elapsed":387,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"9c82801c-be18-41ec-f85a-4c71aa9ebdeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(34.3000)\n","torch.float32\n","<class 'numpy.ndarray'>\n","float64\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(34.3000, dtype=torch.float64)"]},"metadata":{},"execution_count":17}],"source":["import numpy as np\n","a = 34.3\n","b = torch.tensor(a) # python object to tensor obj\n","print(b)\n","print(b.dtype) # .dtype == data type e.g. float32 ...\n","\n","x = np.array( 34.3 )  # np.array ( 34.3 )\n","print(type(x)) # type(x) = x's type numpy.number dimentional array.. \n","print(x.dtype) # datatype. numpy array = float64\n","y = torch.tensor(x)\n","y"]},{"cell_type":"markdown","metadata":{"id":"T2J5oMn2_2An"},"source":["**Check :**  the dtype(data type) is explicitly set at numpy-to-tensor conversion"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBWB2msU_2Ao","executionInfo":{"status":"ok","timestamp":1655877701115,"user_tz":-540,"elapsed":84,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"1dbd205a-7362-4bfd-e0eb-a438b7cfa90e"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 4)\n","tensor([[1, 2, 3, 4],\n","        [5, 6, 7, 8]])\n","torch.Size([2, 4])\n"]}],"source":["x = np.array( [ \n","                [1,2,3,4], \n","                [5,6,7,8]\n","               ]\n","            ) # 2 dimensional array np array가 int타입을 추측함\n","print( x.shape )\n","\n","print( torch.tensor(x) )\n","print( torch.tensor(x).shape ) "]},{"cell_type":"markdown","metadata":{"id":"zt3imrtQ_2As"},"source":["Even, much larger tensor dimension can be handled. "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rp1hTdwr_2As","executionInfo":{"status":"ok","timestamp":1655877701116,"user_tz":-540,"elapsed":52,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"5a8f8dcd-a0b5-49ad-9c0f-1792b4aa3c60"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1, 2, 3, 4],\n","          [5, 6, 7, 8]]]])\n","torch.Size([1, 1, 2, 4])\n"]}],"source":["x = np.array([ [\n","                [ \n","                   [1,2,3,4], \n","                   [5,6,7,8] \n","                ]\n","               ] \n","              ]\n","            ) \n","print( torch.tensor(x) )\n","print( torch.tensor(x).shape ) # [1, 1, 2, 4] -> 가장 바깥쪽, 그 바깥쪽, 2개의 리스트 4개의 데이터"]},{"cell_type":"markdown","metadata":{"id":"EzT7OdNO_2As"},"source":["#### Tensor Types \n","\n","Pytorch tensor supports many numeric types. The summary is shown in below. \n","\n","![image.png](attachment:image.png)\n","\n","Most of case, **float** dtype is the typical choice for setting data type."]},{"cell_type":"markdown","metadata":{"id":"dDVyez6M_2At"},"source":["#### Tensor dtype Conversion \n","\n","Type conversion or setting is conducted with several ways. \n","- by Creation \n","- by Conversion\n","    - .to()\n","    - .type()\n","       \n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Au7C8Wep_2At","executionInfo":{"status":"ok","timestamp":1655877701119,"user_tz":-540,"elapsed":49,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"fe222906-6359-4f4e-d4e3-3ce6697b13ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4.])\n","torch.float32\n"]}],"source":["# by creation\n","x = torch.tensor( [1, 2, 3, 4], dtype=torch.float) # explicitly declare\n","print( x )\n","print( x.dtype )"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWF61HeG_2Au","executionInfo":{"status":"ok","timestamp":1655877701120,"user_tz":-540,"elapsed":47,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"a57b4cb7-6621-44b2-f0d1-dca102dd9940"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4.], dtype=torch.float16)\n","torch.float16\n"]}],"source":["# by creation\n","x = torch.tensor( [1, 2, 3, 4], dtype=torch.float16)\n","print( x )\n","print( x.dtype )"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6T8LBLfH_2Au","executionInfo":{"status":"ok","timestamp":1655877701121,"user_tz":-540,"elapsed":47,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"2e21357d-a527-4205-ad43-420c4ceaf00c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4.])\n","torch.float32\n","tensor([1, 2, 3, 4], dtype=torch.int32)\n","torch.int32\n"]}],"source":["# by explicit conversion by .to()\n","x = torch.tensor( [1, 2, 3, 4], dtype=torch.float)\n","print( x )\n","print( x.dtype ) # float32 = torch.float\n","y = x.to(torch.int)  # .to() is quite useful function in many cases. it is not for only type conversion but also device change. \n","print( y ) \n","print( y.dtype ) # int32 numpy = astype.. pytorch is .to()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lq8DU7e_2Av","executionInfo":{"status":"ok","timestamp":1655877701129,"user_tz":-540,"elapsed":54,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"74c83e01-a2d7-4506-cb9c-09d464e811d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4.])\n","torch.float32\n","tensor([1, 2, 3, 4], dtype=torch.int32)\n","torch.int32\n"]}],"source":["# by explicit conversion by type()\n","x = torch.tensor( [1, 2, 3, 4], dtype=torch.float)\n","print( x )\n","print( x.dtype )\n","y = x.type(torch.int) \n","print( y )\n","print( y.dtype )"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzOKgLSU_2Av","executionInfo":{"status":"ok","timestamp":1655880035186,"user_tz":-540,"elapsed":362,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"eee91a2e-8415-4ac3-b73d-180d43fa4d03"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3., 4.])\n","torch.float32\n","tensor([1, 2, 3, 4], dtype=torch.int16)\n","torch.int16\n"]}],"source":["# you can even specify the type with \"string\" not object\n","x = torch.tensor( [1, 2, 3, 4], dtype=torch.float)\n","print( x )\n","print( x.dtype )\n","OUR_TYPE = \"torch.ShortTensor\"\n","y = x.type(OUR_TYPE)  # <-- string !!\n","print( y )\n","print( y.dtype )"]},{"cell_type":"markdown","metadata":{"id":"14pAcYiT_2Av"},"source":["**Check :** the string type-name is from \"LEGACY CONSTRUCTUR\" of pytorch tensor (see above figure ) "]},{"cell_type":"markdown","metadata":{"id":"Cz99mYzz_2Aw"},"source":["## Tensor Shape"]},{"cell_type":"markdown","metadata":{"id":"4d-c5zy4_2Aw"},"source":["Tensor is a n-dimensional array. Therefore, check and set the shape of tensor are fundamental and cruical operations for handling tensor. Shape operation might be your best and useful tool for deep learning. \n","\n","In here, we will check elemenary shape operations. Some of the advanced topics will be convered in the later of this lecture. \n","We will see \n","- Check shape\n","- Reshape"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-mX3iq8_2Aw","executionInfo":{"status":"ok","timestamp":1655880198386,"user_tz":-540,"elapsed":333,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"d744c87f-2bde-45f7-fb20-a67ea88670af"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","torch.Size([2, 3])\n"]}],"source":["# check shape\n","x = torch.tensor( [ \n","                    [1,2,3],\n","                    [4,5,6]\n","                  ] ) # 2x3 tensor\n","print(x)\n","print(x.shape) "]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHEaGGNk_2Ax","executionInfo":{"status":"ok","timestamp":1655880214458,"user_tz":-540,"elapsed":383,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"84380700-fa4f-45b6-f1d8-7faba5a98219"},"outputs":[{"output_type":"stream","name":"stdout","text":["batch size : 2\n","1st dimension :  3\n","torch.Size([2, 3])\n"]}],"source":["# you can also get the values of each dimension\n","batch_size, dim_1 = x.shape # [2, 3] \n","print( \"batch size :\", batch_size )\n","print( \"1st dimension : \", dim_1 )\n","print( x.size() ) # size가 가지고 있는 tensor가 return 됨"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87wWV63V_2Ay","executionInfo":{"status":"ok","timestamp":1655880432135,"user_tz":-540,"elapsed":302,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"5eaa2ae5-af18-4ba1-dc22-2db05fa24b91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original :  torch.Size([2, 3])\n","Reshaped :  torch.Size([3, 2])\n","Reshaped :  torch.Size([1, 6])\n","Reshaped :  torch.Size([6, 1])\n","tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","-----\n","tensor([1, 2, 3, 4, 5, 6])\n","tensor([[[[[[[[[[1, 2, 3, 4, 5, 6]]]]]]]]]])\n"]}],"source":["# by \"RESHAPE\", you can change tensor shape whatever you want. \n","print(\"Original : \" , x.shape )\n","print(\"Reshaped : \" , x.reshape([3,2]).shape ) # <-- check the result\n","print(\"Reshaped : \" , x.reshape([1,6]).shape ) # <-- check the result\n","print(\"Reshaped : \" , x.reshape([6,1]).shape ) # <-- check the result\n","\n","# reshape() -> input data size , output data size is same.. 2x3 -> 6x1... only same\n","print(x)\n","print(\"-----\")\n","print(x.reshape([6]))\n","print(x.reshape([1,1,1,1,1,1,1,1,1,6]))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSle_Ejh_2Ay","executionInfo":{"status":"ok","timestamp":1655880464912,"user_tz":-540,"elapsed":301,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"230f81db-a2c5-4519-faf2-baf5217d3242"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original :  torch.Size([2, 3])\n","Reshaped :  torch.Size([6, 1])\n"]}],"source":["# but reshape is only allowed when the total size is same. \n","print(\"Original : \" , x.shape )\n","print(\"Reshaped : \" , x.reshape([6,1]).shape ) # <-- it will cause 'ERROR' "]},{"cell_type":"markdown","metadata":{"id":"Di0ovr6N_2Ay"},"source":["#### (ADVANCED) reshape and view "]},{"cell_type":"markdown","metadata":{"id":"mK-ZALMh_2Az"},"source":["Pytorch support 'view' function for shaping operation. The functionality is almost same as reshape, but the memory usuage is different. \n","\n","Following description is from pytorch document.\n","![image.png](attachment:image.png)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8yEfsna_2Az","executionInfo":{"status":"ok","timestamp":1655880589212,"user_tz":-540,"elapsed":321,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"a1a02403-6a17-450d-ba43-025e26da590d"},"outputs":[{"output_type":"stream","name":"stdout","text":["x : torch.Size([4, 4])\n","y : torch.Size([16])\n","z : torch.Size([2, 8])\n"]}],"source":["x = torch.randn(4, 4)\n","print( \"x :\", x.size() )\n","y = x.view(16)\n","print( \"y :\", y.size() ) \n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions 8로부터 -1을 추측함, 즉 -1이 8이됫기때문에 -1은 2가 됨.\n","print( \"z :\", z.size() )"]},{"cell_type":"markdown","metadata":{"id":"Cu3guZHo_2Az"},"source":["View is a just mirror of data with another shape. So, it does not change data it self. "]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pM2g0qe2_2Az","executionInfo":{"status":"ok","timestamp":1655880679054,"user_tz":-540,"elapsed":409,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"91c98542-c8d5-4c16-f0a8-b36ea27c2a50"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","a :  torch.Size([3, 2, 4])\n","tensor([[[ 1,  2],\n","         [ 3,  4],\n","         [ 5,  6],\n","         [ 7,  8]],\n","\n","        [[11, 12],\n","         [13, 14],\n","         [15, 16],\n","         [17, 18]],\n","\n","        [[21, 22],\n","         [23, 24],\n","         [25, 26],\n","         [27, 28]]])\n"]}],"source":["a = torch.tensor( [\n","                        [\n","                            [ 1, 2, 3, 4 ], \n","                            [ 5, 6, 7, 8 ], \n","                        ],\n","                        [\n","                            [ 11, 12, 13, 14 ], \n","                            [ 15, 16, 17, 18 ], \n","                        ],\n","                        [\n","                            [ 21, 22, 23, 24 ], \n","                            [ 25, 26, 27, 28 ], \n","                        ],\n","                    ]\n","                  )\n","print( a )\n","print( \"a : \", a.size() )\n","b = a.view(3, 4, 2)  # change shape  b는 a를 shape를 바꿔서 바라보고 있다. 즉 실제하는 데이터가 아님\n","print(b)"]},{"cell_type":"markdown","metadata":{"id":"taa8vDbs_2A0"},"source":["Let's change the original data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cx5Yp4xJ_2A0","outputId":"9eb06a83-693d-4459-8fd5-3a3f174a6905"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","tensor([[11, 12, 13, 14],\n","        [15, 16, 17, 18]])\n","[before change]\n","b :  tensor([[[ 1,  2],\n","         [ 3,  4],\n","         [ 5,  6],\n","         [ 7,  8]],\n","\n","        [[11, 12],\n","         [13, 14],\n","         [15, 16],\n","         [17, 18]],\n","\n","        [[21, 22],\n","         [23, 24],\n","         [25, 26],\n","         [27, 28]]])\n","---------------- \n","tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[51, 52, 53, 54],\n","         [55, 56, 57, 58]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","[after change]\n","b :  tensor([[[ 1,  2],\n","         [ 3,  4],\n","         [ 5,  6],\n","         [ 7,  8]],\n","\n","        [[51, 52],\n","         [53, 54],\n","         [55, 56],\n","         [57, 58]],\n","\n","        [[21, 22],\n","         [23, 24],\n","         [25, 26],\n","         [27, 28]]])\n"]}],"source":["a = torch.tensor( [\n","                        [\n","                            [ 1, 2, 3, 4 ], \n","                            [ 5, 6, 7, 8 ], \n","                        ],\n","                        [\n","                            [ 11, 12, 13, 14 ], \n","                            [ 15, 16, 17, 18 ], \n","                        ],\n","                        [\n","                            [ 21, 22, 23, 24 ], \n","                            [ 25, 26, 27, 28 ], \n","                        ],\n","                    ]\n","                  )\n","print(a)\n","print(a[1])\n","b = a.view(3, 4, 2)  # change shape\n","print(\"[before change]\")\n","print(\"b : \", b)\n","print( \"---------------- \")\n","a[1] = torch.tensor( [[51, 52, 53, 54],\n","                     [55, 56, 57, 58]] ) # <-- assign new value\n","print(a)\n","print(\"[after change]\")\n","print(\"b : \", b) # view는 메모리상의 데이터는 그대로 존재하지만 바라보는 방향만 바꿈"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY1FwppV_2A1","outputId":"490fd552-a0df-4a39-b7ab-a3bca4f4f958"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1,  2],\n","         [ 3,  4],\n","         [ 5,  6],\n","         [ 7,  8]],\n","\n","        [[51, 52],\n","         [53, 54],\n","         [55, 56],\n","         [57, 58]],\n","\n","        [[21, 22],\n","         [23, 24],\n","         [25, 26],\n","         [27, 28]]])\n"]}],"source":["print(b)"]},{"cell_type":"markdown","metadata":{"id":"AqmA5QPx_2A2"},"source":["Let's try to change value in 'viewed' tensor. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThCgL7Oi_2A2","outputId":"c7591ac0-1ed3-4b4a-97e6-2a34f63919cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[  1,   2,   3,   4],\n","         [  5,   6,   7,   8]],\n","\n","        [[151, 152, 153, 154],\n","         [155, 156, 157, 158]],\n","\n","        [[ 21,  22,  23,  24],\n","         [ 25,  26,  27,  28]]])\n"]}],"source":["b[1] = torch.tensor([[151, 152],\n","                    [153, 154],\n","                    [155, 156],\n","                    [157, 158]]) #뷰의 데이터를 바꾼다면? a도 바뀜\n","print(a) \n","#b와 a는 공통된 메모리를 공유하기 떄문에 b나 a의 메모리값을 바꾼다면 같이 바뀜. 단 바라보는 방향이 다르기 떄문에 shape는 다를 수 있다."]},{"cell_type":"markdown","metadata":{"id":"Vi20gP2p_2A2"},"source":["## Tensor Device Change\n","\n","PyTorch support GPU calcualtion. We can transfer data in CPU to GPU or vice versa.\n"," - CPU to GPU\n"," - GPU to CPU\n"," \n","**NOTE** You need 'GPU' to run the following section. \n","\n","\n","google -- colab "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xbdchEg_2A3","executionInfo":{"status":"ok","timestamp":1655881597163,"user_tz":-540,"elapsed":274,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"23275484-f3bf-47ac-c3b4-d4d347f040e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 4], device='cuda:0')\n","cuda:0\n","tensor([1, 2, 3, 4])\n","cpu\n","tensor([1, 2, 3, 4])\n","cpu\n"]}],"source":["import torch\n","#CPU to GPU @ creation\n","a = torch.tensor([1,2,3,4], device='cuda:0') # 파이토치는 디바이스를 넣어줄수이음 device = 'cuda | cpu' colab = cuda:0 is all\n","print(a)\n","print(a.device)\n","b = torch.tensor([1,2,3,4], device='cpu')\n","print(b)\n","print(b.device)\n","c = torch.tensor([1,2,3,4]) # <-- default device : cpu \n","print(c)\n","print(c.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNByO1oc_2A4","outputId":"8606422a-c11a-463a-cea2-6ec6e9744b37"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3, 4])\n","cpu\n","tensor([1, 2, 3, 4], device='cuda:0')\n","cuda:0\n","----------try to change b-----------\n","a:  tensor([1, 2, 3, 4])\n","b:  tensor([ 1,  2,  3, 14], device='cuda:0')\n"]}],"source":["#CPU to GPU @ after creation\n","a = torch.tensor([1,2,3,4])\n","print(a)\n","print(a.device)\n","b = a.to('cuda') # <--- .to( ~~~ ) \n","print(b)\n","print(b.device)\n","print(\"----------try to change b-----------\")\n","b[3] = 14\n","print(\"a: \", a)\n","print(\"b: \", b) # <-- you will see a and b are not same object any more\n"]},{"cell_type":"markdown","metadata":{"id":"dMPITvCc_2A5"},"source":["## Tensor @ GPU data to CPU data \n","\n","We need some operations to fetch GPU data to CPU area. \n"," - GPU data to CPU\n","     - torch.tensor @GPU --> torch.tensor @CPU --> python object @CPU\n","     - torch.tensor @GPU --> torch.tensor @CPU --> numpy object  @CPU"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SHmO0vH_2A6","executionInfo":{"status":"ok","timestamp":1655881670349,"user_tz":-540,"elapsed":298,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"e31c3287-b945-4815-a43e-38c3275ccb76"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]], device='cuda:0')\n","cuda:0\n"]}],"source":["a = torch.tensor( [\n","                        [\n","                            [ 1, 2, 3, 4 ], \n","                            [ 5, 6, 7, 8 ], \n","                        ],\n","                        [\n","                            [ 11, 12, 13, 14 ], \n","                            [ 15, 16, 17, 18 ], \n","                        ],\n","                        [\n","                            [ 21, 22, 23, 24 ], \n","                            [ 25, 26, 27, 28 ], \n","                        ],\n","                    ]\n","                  ).to('cuda') # <-- GPU\n","print(a)\n","print(a.device)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoCG725z_2A6","executionInfo":{"status":"ok","timestamp":1655881739648,"user_tz":-540,"elapsed":298,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"dd43148b-e925-4653-f322-4c77a8ca1dde"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","<class 'torch.Tensor'>\n","cpu\n"]}],"source":["b = a.cpu() # a data cpu로 내려오서 cpu에 저장. 그럼 to('cpu')랑 같은건가?\n","#b = a.to('cpu') # 같다!\n","print(b)\n","print(type(b))   # <-- torch.tensor @CPU\n","print(b.device)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GkEEJgf_2A7","executionInfo":{"status":"ok","timestamp":1655881777229,"user_tz":-540,"elapsed":294,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"0ab8441d-0bdd-4f1a-f95b-2b4d14bd0f1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[[1, 2, 3, 4], [5, 6, 7, 8]], [[11, 12, 13, 14], [15, 16, 17, 18]], [[21, 22, 23, 24], [25, 26, 27, 28]]]\n","<class 'list'>\n"]}],"source":["c = b.tolist()   # CPU torch.tensor --> python object .tolist()\n","print(c) \n","print(type(c))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOwZbuAT_2A8","outputId":"c6ec9662-268e-4031-8a23-15001ed429fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'numpy.ndarray'>\n"]}],"source":["#a.numpy()  #< -- cause error numpy의 memory는 cpu만 지원함\n","a.cpu().numpy() # cpu로 내린다음 numpy 또는 python array , .tolist() 로 바꾼후 연산하여야함.\n","print( type(a.cpu().numpy() ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUXBqjlr_2A9","outputId":"0bb28fc3-6b9d-46a8-dbee-1fa8aaa551c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 1  2  3  4]\n","  [ 5  6  7  8]]\n","\n"," [[11 12 13 14]\n","  [15 16 17 18]]\n","\n"," [[21 22 23 24]\n","  [25 26 27 28]]]\n","<class 'numpy.ndarray'>\n"]}],"source":["c = b.numpy()   # CPU torch.tensor --> numpy object\n","print(c)\n","print(type(c))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8W-LIIyI_2A9","outputId":"8cee526b-53ab-4ad6-91fb-a261ed5c1417"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 1  2  3  4]\n","  [ 5  6  7  8]]\n","\n"," [[11 12 13 14]\n","  [15 16 17 18]]\n","\n"," [[21 22 23 24]\n","  [25 26 27 28]]]\n","<class 'numpy.ndarray'>\n"]}],"source":["# one liner\n","c = a.cpu().numpy()\n","print(c)\n","print(type(c))"]},{"cell_type":"markdown","metadata":{"id":"6J1cmfIF_2A9"},"source":["When we want to get scalar value directly, there is item() funtion. "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDkCAvkI_2A-","executionInfo":{"status":"ok","timestamp":1655882954694,"user_tz":-540,"elapsed":294,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"80ef94b0-c8b8-4697-80ba-232d9a12daae"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 2, 3, 4], device='cuda:0')\n","cuda:0\n"]}],"source":["a = torch.tensor( [1,2,3,4], device='cuda')\n","print(a)\n","print(a.device)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"j8TD_v1H_2A-","executionInfo":{"status":"error","timestamp":1655882956854,"user_tz":-540,"elapsed":769,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"0c315a3f-5622-45ac-f247-9355162edb9e"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-7844d80a2c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# <-- it will cause ERROR -- since item() support only scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"]}],"source":["a.item()  # <-- it will cause ERROR -- since item() support only scalars"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcOLNLDf_2A-","executionInfo":{"status":"ok","timestamp":1655882973086,"user_tz":-540,"elapsed":365,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"bf473b8b-ede4-40e3-da94-082564aac6a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1], device='cuda:0')\n","cuda:0\n","-----\n","1\n","<class 'int'>\n"]}],"source":["a = torch.tensor( [1], device='cuda') # scala data는 바로나옴\n","print(a)\n","print(a.device)\n","print(\"-----\")\n","b = a.item()  \n","print(b)\n","print(type(b)) # <- python object type"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlUbXs7N_2A-","outputId":"f7cb550b-3b6c-4dab-c844-0a435739c649"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(101.3434, device='cuda:0')\n","cuda:0\n","-----\n","101.34339904785156\n","<class 'float'>\n"]}],"source":["a = torch.tensor(101.3434, device='cuda')\n","print(a)\n","print(a.device)\n","print(\"-----\")\n","b = a.item()  \n","print(b)\n","print(type(b)) # <- python object type"]},{"cell_type":"markdown","metadata":{"id":"MhBIJS8a_2A_"},"source":["## 1 to N Operations\n","a Tensor → a list of Tensors "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCuxfz5N_2A_","executionInfo":{"status":"ok","timestamp":1655883029816,"user_tz":-540,"elapsed":292,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"9c40003d-cfe2-40df-fbcc-ef560fad2546"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","torch.Size([3, 2, 4])\n"]}],"source":["a = torch.tensor( [\n","                        [\n","                            [ 1, 2, 3, 4 ], \n","                            [ 5, 6, 7, 8 ], \n","                        ],\n","                        [\n","                            [ 11, 12, 13, 14 ], \n","                            [ 15, 16, 17, 18 ], \n","                        ],\n","                        [\n","                            [ 21, 22, 23, 24 ], \n","                            [ 25, 26, 27, 28 ], \n","                        ],\n","                  ]\n","                  )\n","print(a)\n","print(a.shape)"]},{"cell_type":"markdown","metadata":{"id":"FqNGAsYx_2A_"},"source":["Let's split the data with 3 parts"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMHJUqGn_2BA","executionInfo":{"status":"ok","timestamp":1655883169709,"user_tz":-540,"elapsed":276,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"537d6a0a-87fc-42a7-cf50-a4232be54a89"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[[1, 2, 3, 4],\n","         [5, 6, 7, 8]]]), tensor([[[11, 12, 13, 14],\n","         [15, 16, 17, 18]]]), tensor([[[21, 22, 23, 24],\n","         [25, 26, 27, 28]]]))\n","tensor([[[1, 2, 3, 4],\n","         [5, 6, 7, 8]]])\n","-----\n","torch.Size([1, 2, 4])\n","torch.Size([1, 2, 4])\n","torch.Size([1, 2, 4])\n"]}],"source":["a_l_tensors = torch.chunk(a, chunks=3, dim=0) # return a list of tensor # .chunk(tensor, chunks' count, split's dim e.g. 0)\n","# a_1_tensors = splited tensors' list\n","print(a_l_tensors)\n","print(a_l_tensors[0])\n","print(\"-----\")\n","print(a_l_tensors[0].shape) # 1, 2, 4\n","print(a_l_tensors[1].shape)\n","print(a_l_tensors[2].shape)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59l9coAR_2BA","executionInfo":{"status":"ok","timestamp":1655883223971,"user_tz":-540,"elapsed":318,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"7117f3c3-8cdb-4cc6-c501-c58263626be0"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[[ 1],\n","         [ 5]],\n","\n","        [[11],\n","         [15]],\n","\n","        [[21],\n","         [25]]]), tensor([[[ 2],\n","         [ 6]],\n","\n","        [[12],\n","         [16]],\n","\n","        [[22],\n","         [26]]]), tensor([[[ 3],\n","         [ 7]],\n","\n","        [[13],\n","         [17]],\n","\n","        [[23],\n","         [27]]]), tensor([[[ 4],\n","         [ 8]],\n","\n","        [[14],\n","         [18]],\n","\n","        [[24],\n","         [28]]]))\n","tensor([[[ 2],\n","         [ 6]],\n","\n","        [[12],\n","         [16]],\n","\n","        [[22],\n","         [26]]])\n","-----\n","torch.Size([3, 2, 1])\n","torch.Size([3, 2, 1])\n","torch.Size([3, 2, 1])\n","torch.Size([3, 2, 1])\n"]}],"source":["print(  torch.chunk(a, chunks=4, dim=-1)  ) # return a list of tensor -1 은 가장 마지막 디멘션. = \n","print(  torch.chunk(a, chunks=4, dim=-1)[1]  )\n","print(\"-----\")\n","print(  torch.chunk(a, chunks=4, dim=-1)[0].shape  )\n","print(  torch.chunk(a, chunks=4, dim=-1)[1].shape  )\n","print(  torch.chunk(a, chunks=4, dim=-1)[2].shape  )\n","print(  torch.chunk(a, chunks=4, dim=-1)[3].shape  )\n"]},{"cell_type":"markdown","metadata":{"id":"pGNm1aXP_2BA"},"source":["## N to 1 Operations\n","a list of Tensors →  a Tensor \n","- by cat\n","- by stack"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOvDafvz_2BA","executionInfo":{"status":"ok","timestamp":1655883296942,"user_tz":-540,"elapsed":299,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"ef085f5f-c398-4305-8174-314a4c982b9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[[1, 2, 3, 4],\n","         [5, 6, 7, 8]]]), tensor([[[11, 12, 13, 14],\n","         [15, 16, 17, 18]]]), tensor([[[21, 22, 23, 24],\n","         [25, 26, 27, 28]]]))\n","----\n","torch.Size([1, 2, 4])\n","torch.Size([1, 2, 4])\n","torch.Size([1, 2, 4])\n"]}],"source":["print(a_l_tensors)\n","print(\"----\")\n","print(a_l_tensors[0].shape)\n","print(a_l_tensors[1].shape)\n","print(a_l_tensors[2].shape)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dmtymhz3_2BA","executionInfo":{"status":"ok","timestamp":1655883319448,"user_tz":-540,"elapsed":3,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"46d8c349-64c4-470d-ada2-b56d93336ce8"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","torch.Size([3, 2, 4])\n"]}],"source":["b = torch.cat(a_l_tensors) # cat() tuple of tensors \n","print(b)\n","print(b.shape) # <-- You will see recovered shape of a"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLHpADnh_2BB","outputId":"795eb3be-3b8d-4141-cf23-5e8671454266"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8],\n","         [11, 12, 13, 14],\n","         [15, 16, 17, 18],\n","         [21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","torch.Size([1, 6, 4])\n"]}],"source":["# but you can concatenate in differnt ways\n","c = torch.cat(a_l_tensors, dim=1)\n","print(c)\n","print(c.shape) # <-- You will see different shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pih_mm3y_2BB","outputId":"d91f335b-a142-4c33-8b2d-e1258da66cbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1,  2,  3,  4, 11, 12, 13, 14, 21, 22, 23, 24],\n","         [ 5,  6,  7,  8, 15, 16, 17, 18, 25, 26, 27, 28]]])\n","torch.Size([1, 2, 12])\n"]}],"source":["# but you can concatenate in differnt ways\n","#d = torch.cat(a_l_tensors, dim=2)\n","d = torch.cat(a_l_tensors, dim=-1) # <- get the same result\n","print(d)\n","print(d.shape) # <-- You will see different shape"]},{"cell_type":"markdown","metadata":{"id":"VL-PNb7u_2BB"},"source":["stack works little bit differently. \n","![image.png](attachment:image.png)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_h7LAGi3_2BB","executionInfo":{"status":"ok","timestamp":1655883590161,"user_tz":-540,"elapsed":279,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"4647e1d3-b81e-421d-89b7-0ee44742abce"},"outputs":[{"output_type":"stream","name":"stdout","text":["original shape of a :  torch.Size([3, 2, 4])\n","(tensor([[[1, 2, 3, 4],\n","         [5, 6, 7, 8]]]), tensor([[[11, 12, 13, 14],\n","         [15, 16, 17, 18]]]), tensor([[[21, 22, 23, 24],\n","         [25, 26, 27, 28]]]))\n"," ---------- \n","tensor([[[[ 1,  2,  3,  4],\n","          [ 5,  6,  7,  8]]],\n","\n","\n","        [[[11, 12, 13, 14],\n","          [15, 16, 17, 18]]],\n","\n","\n","        [[[21, 22, 23, 24],\n","          [25, 26, 27, 28]]]])\n","torch.Size([3, 1, 2, 4])\n"]}],"source":["print(\"original shape of a : \", a.shape)\n","print( a_l_tensors )\n","print( \" ---------- \" ) \n","e = torch.stack(a_l_tensors)\n","print(e)\n","print(e.shape) # <-- You will see another dimension at second "]},{"cell_type":"markdown","metadata":{"id":"th7M96G6_2BC"},"source":["## Dimension Operations\n","\n","We sometimes need manipulation dimension directly. There are many operations. \n"," - transpose\n"," - permutation \n"," - squeeze\n"," - unsqueeze "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xua5LfBl_2BC"},"outputs":[],"source":["# transpose 차원의 데이터를 swapping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7qJfatU0_2BC","outputId":"8f5f1674-6e9c-40d3-e364-9536016c360c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]]])\n","torch.Size([3, 2, 4])\n"]}],"source":["a = torch.tensor( [\n","                        [\n","                            [ 1, 2, 3, 4 ], \n","                            [ 5, 6, 7, 8 ], \n","                        ],\n","                        [\n","                            [ 11, 12, 13, 14 ], \n","                            [ 15, 16, 17, 18 ], \n","                        ],\n","                        [\n","                            [ 21, 22, 23, 24 ], \n","                            [ 25, 26, 27, 28 ], \n","                        ],\n","                  ]\n","                  )\n","print(a)\n","print(a.shape)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrVJqffG_2BD","executionInfo":{"status":"ok","timestamp":1655884025280,"user_tz":-540,"elapsed":295,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"0f900714-0d05-4ea6-aa16-b3d73aa0f670"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 2, 4])\n","torch.Size([2, 3, 4])\n","tensor([[[ 1,  2,  3,  4],\n","         [11, 12, 13, 14],\n","         [21, 22, 23, 24]],\n","\n","        [[ 5,  6,  7,  8],\n","         [15, 16, 17, 18],\n","         [25, 26, 27, 28]]])\n"]}],"source":["print(a.shape)\n","b = torch.transpose(a, 0, 1)\n","print(b.shape)\n","print(b)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zxugm_XS_2BD","outputId":"ab184cc2-992b-4f64-a8c6-f579560e2b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 2, 4])\n","torch.Size([4, 2, 3])\n","tensor([[[ 1, 11, 21],\n","         [ 5, 15, 25]],\n","\n","        [[ 2, 12, 22],\n","         [ 6, 16, 26]],\n","\n","        [[ 3, 13, 23],\n","         [ 7, 17, 27]],\n","\n","        [[ 4, 14, 24],\n","         [ 8, 18, 28]]])\n"]}],"source":["print(a.shape)\n","c = torch.transpose(a, 0, 2) # 0과 2차원을 바꾸면 324 -> 423\n","print(c.shape)\n","print(c)"]},{"cell_type":"markdown","metadata":{"id":"tIvkz2SI_2BD"},"source":["You can also swap all the dimensions at once by **permutation()**."]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WpMfM5k_2BE","executionInfo":{"status":"ok","timestamp":1655884147738,"user_tz":-540,"elapsed":292,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"2a0625af-1552-442f-896e-9755fc0d47c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original shape of a  torch.Size([3, 2, 4])\n","torch.Size([4, 3, 2])\n","tensor([[[ 1,  5],\n","         [11, 15],\n","         [21, 25]],\n","\n","        [[ 2,  6],\n","         [12, 16],\n","         [22, 26]],\n","\n","        [[ 3,  7],\n","         [13, 17],\n","         [23, 27]],\n","\n","        [[ 4,  8],\n","         [14, 18],\n","         [24, 28]]])\n"]}],"source":["print(\"Original shape of a \", a.shape)\n","d = a.permute(2, 0, 1) # d라는 데이터의 1,2,3 차원에 데이터는  a라는 데이터의 세번째, 첫번째, 두번째 차원으로 이루어져있다.\n","print(d.shape)\n","print(d)"]},{"cell_type":"markdown","metadata":{"id":"aB-dq7J3_2BE"},"source":["There are some differences between view, reshape, transpose, permuation in pytorch. \n","Following descriptions are from the https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/ .\n"]},{"cell_type":"markdown","metadata":{"id":"GYs_jPIc_2BE"},"source":["- Both view() and reshape() can be used to change the size or shape of tensors. But they are slightly different.\n","- torch.reshape may return a copy or a view of the original tensor\n","- transpose(), like view() can also be used to change the shape of a tensor and it also returns a new tensor sharing the data with the original tensor\n","- One difference is that view() can only operate on contiguous tensor and the returned tensor is still contiguous\n","- \"Contiguous \" : the neighboring elements in the tensor are actually next to each other in memory.\n","- permute() and tranpose() are similar. transpose() can only swap two dimension. But permute() can swap all the dimensions. "]},{"cell_type":"markdown","metadata":{"id":"u19Ip2dl_2BE"},"source":["Dimension adding and deleting are supported by squeeze and unsqueeze easily. \n"]},{"cell_type":"markdown","metadata":{"id":"tldGv2xo_2BE"},"source":["#### Squeeze"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_0Nv9wN_2BE","executionInfo":{"status":"ok","timestamp":1655884266097,"user_tz":-540,"elapsed":289,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"1f15b8f1-ed32-4e59-8f3b-05b6b98809a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1, 2, 1, 2])\n"]}],"source":["x = torch.zeros(2, 1, 2, 1, 2)\n","#x\n","print(x.shape)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38qicAnn_2BF","executionInfo":{"status":"ok","timestamp":1655884305615,"user_tz":-540,"elapsed":314,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"4c1f88eb-dd49-4fda-8c95-e80ce79ba913"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0., 0.],\n","         [0., 0.]],\n","\n","        [[0., 0.],\n","         [0., 0.]]])\n","torch.Size([2, 2, 2])\n"]}],"source":["y = torch.squeeze(x)\n","print(y)\n","print(y.shape) # <-- you will see 1 (empty-dimension) is removed "]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAkmZZqe_2BF","executionInfo":{"status":"ok","timestamp":1655884335597,"user_tz":-540,"elapsed":285,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"f430e668-8253-4619-f466-d3263770972f"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[0., 0.]],\n","\n","         [[0., 0.]]],\n","\n","\n","        [[[0., 0.]],\n","\n","         [[0., 0.]]]])\n","torch.Size([2, 2, 1, 2])\n"]}],"source":["# or you can specify the squeezing dimension\n","y = torch.squeeze(x, dim=1)\n","print(y)\n","print(y.shape) # <-- you will see dim=1 is removed "]},{"cell_type":"markdown","metadata":{"id":"HDTJ6ZPl_2BF"},"source":["#### Unsqueeze"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWc6JQce_2BF","executionInfo":{"status":"ok","timestamp":1655884387199,"user_tz":-540,"elapsed":408,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"87ab1649-50fd-49c7-d507-cc9b6bd1ebb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 2, 1, 2])\n","torch.Size([2, 1, 2, 1, 2])\n"]}],"source":["print(y.shape)\n","z = y.unsqueeze(dim=1) # 1번째 dimension에 dummy dimension을 넣어준다.\n","print(z.shape)"]},{"cell_type":"markdown","metadata":{"id":"KTKNhWJj_2BF"},"source":["## Tensor Indexing\n","\n","There are many intutive examples to illustrate the indexing concept. \n","I borrowed figures and examples from \n"," - https://medium.com/analytics-vidhya/understanding-indexing-with-pytorch-gather-33717a84ebc4\n"," "]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaWFaH3G_2BG","executionInfo":{"status":"ok","timestamp":1655884407089,"user_tz":-540,"elapsed":316,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"de440f65-64b2-4c69-8bd0-e798c7a21794"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 10])\n"]}],"source":["x = [ [ 0,1,2,3,4,5,6,7,8,9 ], \n","      [ 10,11,12,13,14,15,16,17,18,19 ], \n","      [ 20,21,22,23,24,25,26,27,28,29 ], \n","      [ 30,31,32,33,34,35,36,37,38,39 ], \n","    ]\n","x = torch.tensor(x)\n","x       \n","print(x.shape)"]},{"cell_type":"markdown","metadata":{"id":"KMxI0IR__2BG"},"source":["#### indexing with \"   :  \"\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FZO_plF_2BG","executionInfo":{"status":"ok","timestamp":1655884457460,"user_tz":-540,"elapsed":281,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"198f0fcc-0943-4fed-dc04-ab36e137bd86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 3, 13, 23, 33])"]},"metadata":{},"execution_count":38}],"source":["x[:, 3] #: means all "]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lxEbhh8_2BG","executionInfo":{"status":"ok","timestamp":1655884480147,"user_tz":-540,"elapsed":286,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"36574df4-cea8-4011-f6c4-b869303fa122"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])"]},"metadata":{},"execution_count":40}],"source":["x[3,:] # row columns -> 3's row all data "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"_NvaPijI_2BG","outputId":"06c60e0a-780c-4f9b-d3ae-50e442f1e272"},"outputs":[{"data":{"text/plain":["tensor([[ 2,  3,  4],\n","        [12, 13, 14],\n","        [22, 23, 24],\n","        [32, 33, 34]])"]},"execution_count":268,"metadata":{},"output_type":"execute_result"}],"source":["x[:, 2:5] # row columns 2:5 2인덱스부터 5인덱스까지"]},{"cell_type":"markdown","metadata":{"id":"3XOGbKPS_2BH"},"source":["#### indexing with \" -1 \""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-Yjo8NG_2BH","outputId":"9aa4e589-4bfd-46fe-c427-d49c690f40e8"},"outputs":[{"data":{"text/plain":["tensor([ 9, 19, 29, 39])"]},"execution_count":269,"metadata":{},"output_type":"execute_result"}],"source":["x[:, -1] #-1은 마지막 columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXf1qULj_2BH","outputId":"b3bce2de-df9d-425b-ab32-c4525738ad83"},"outputs":[{"data":{"text/plain":["tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])"]},"execution_count":270,"metadata":{},"output_type":"execute_result"}],"source":["x[-1, :] # -1은 마지막 rows"]},{"cell_type":"markdown","metadata":{"id":"52rPOrMx_2BH"},"source":["Sometimes, you can just index the element - what you want"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y73oIUtX_2BH","executionInfo":{"status":"ok","timestamp":1655884575769,"user_tz":-540,"elapsed":332,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"45d99ecb-0de5-4eb6-b8c2-db93845a3987"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 10])\n","tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n","        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n","        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])\n","---\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 3,  7,  1,  4],\n","        [13, 17, 11, 14],\n","        [23, 27, 21, 24],\n","        [33, 37, 31, 34]])"]},"metadata":{},"execution_count":41}],"source":["x = [ [ 0,  1, 2, 3, 4, 5, 6, 7, 8, 9 ], \n","      [ 10,11,12,13,14,15,16,17,18,19 ], \n","      [ 20,21,22,23,24,25,26,27,28,29 ], \n","      [ 30,31,32,33,34,35,36,37,38,39 ], \n","    ]\n","x = torch.tensor(x)\n","print(x.shape)\n","indices = torch.LongTensor([3,7,1,4]) # 3,7,1,4순서로 가져와라 indice가 tensor임\n","print(x)\n","print(\"---\")\n","x[:,indices] # indice를 indexing 할 수 있다. "]},{"cell_type":"markdown","metadata":{"id":"kWqR8BA-_2BH"},"source":["## Reduce Operations\n","\n","There are many reducing operations to select item or reduce tensor values \n"," - min, max, mean\n"," - argmax, argmin "]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqLDcGOS_2BI","executionInfo":{"status":"ok","timestamp":1655886703107,"user_tz":-540,"elapsed":470,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"a3a2ae10-efe6-46c6-a11f-53530cedd608"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 1,  2,  3,  4],\n","         [ 5,  6,  7,  8]],\n","\n","        [[21, 22, 23, 24],\n","         [25, 26, 27, 28]],\n","\n","        [[11, 12, 13, 14],\n","         [15, 16, 17, 18]]])\n","torch.Size([3, 2, 4])\n"]}],"source":["a = torch.tensor( [\n","                        [\n","                            [ 1, 2, 3, 4 ], \n","                            [ 5, 6, 7, 8 ], \n","                        ],\n","                        [\n","                            [ 21, 22, 23, 24 ], \n","                            [ 25, 26, 27, 28 ], \n","                        ],\n","                        [\n","                            [ 11, 12, 13, 14 ], \n","                            [ 15, 16, 17, 18 ], \n","                        ],\n","                        \n","                  ]\n","                  )\n","print(a)\n","print(a.shape)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VY8p25uE_2BI","executionInfo":{"status":"ok","timestamp":1655885452490,"user_tz":-540,"elapsed":392,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"45f36224-b0a9-46ff-dc02-bd0464a0f290"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(28)"]},"metadata":{},"execution_count":42}],"source":["torch.max(a)   # <-- find best value over all elements in a tensor"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jq6GMxgW_2BI","executionInfo":{"status":"ok","timestamp":1655886707020,"user_tz":-540,"elapsed":352,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"29c6a36d-4c6d-44c2-ff8d-7d6fa77e798e"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.return_types.max(\n","values=tensor([[ 4,  8],\n","        [24, 28],\n","        [14, 18]]),\n","indices=tensor([[3, 3],\n","        [3, 3],\n","        [3, 3]]))\n","shape :  torch.Size([3, 2])\n"]}],"source":["m = torch.max(a, dim=2)\n","print(m) # <-- note that .max() return tuple ( values, indices ) \n","print(\"shape : \", m.values.shape)"]},{"cell_type":"markdown","metadata":{"id":"ihgnFzq5_2BI"},"source":["#### argmax and argmin get indices of max or min directly "]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UELv-kWO_2BJ","executionInfo":{"status":"ok","timestamp":1655886801892,"user_tz":-540,"elapsed":4,"user":{"displayName":"정진우","userId":"02706839958698409454"}},"outputId":"0b6a7de9-92c8-4f73-eb05-3015016da5aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[3, 3],\n","        [3, 3],\n","        [3, 3]])"]},"metadata":{},"execution_count":50}],"source":["torch.argmax(a, dim=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSP_aTb7_2BJ"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Tensor Operation - Tutorial.ipynb","provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}